
The ingestionThroughChunk.sh script help you to ingest large files into the MMS.
It implements two steps:
1.  ingest the Workflow containing the Add-Content Task
2.	split the large file in little pieces and ingest them one by one

A prerequisite is the installation of jq
	- i.e.: sudo apt-get -y install jq

Usage: ./ingestionThroughChunk.sh <mmsUserKey> <mmsAPIKey> <title> <ingester> <retention> <binaryFilePathName> [<continueFromIndex>]

<mmsUserKey>: the mms key identifying the user
<mmsAPIKey>: the mms key identifying the user and the workspace
<title>: the title of the content
<ingester>: the ingester of the content
<retention>: the retention of the content (i.e.: 10d means 10 days, 3M means 3 months, 1y means 1 year)
<binaryFilePathName>: pathname of the content to be ingested
<continueFromIndex>: this is optional, it is used to continue the upload of a content when the script is interrupted. For example, if the script is interrupted when it was uploading the chunk nr. 100 (i.e. the last message was IngestionNumber 100/171), in order to continue, this parameter has to be set to 100

Examples:
./ingestionThroughChunk.sh 10 HNVsOoVhHx0WNIxFu-ThBA1vAPEKWsxneGgze6TodfCj8pNouN2apCURJyaGdNz VTS_01_4_4k pippo 10y ../VTS_01_4_4k.mkv

nohup ./ingestionThroughChunk.sh 10 HNVOoVhHx0yoWNIxFu-ThBA1vAPEKWSxneGgze6eAodfCj8pNouN2apCURJyaGdNz VTS_01_4_4k pippo 10y ../VTS_01_4_4k.mkv &
tail -f nohup.out 

Options:
1. in case you want to use a specific "encoding profiles set"
	edit the helper/ingestionWorkflow.json file and replace the "encodingProfileLabel" field with the "encodingProfilesSetLabel" field and set his value
2. in case you want to use a specific "encoders pool"
	edit the helper/ingestionWorkflow.json file and add the "encodersPool" field to the "task->onSuccess->task->parameters->tasks[@type=Encode]->parameters" json object


